{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] {'python': '3.12.7 | packaged by Anaconda, Inc. |', 'platform': 'macOS-15.6.1-arm64-arm-64bit', 'cpu_count': 8, 'ram_gb': 17.18, 'numpy': '1.26.4', 'pandas': '2.2.2', 'matplotlib': '3.9.2', 'scipy': 'scipy:1.13.1', 'seaborn': '0.13.2', 'tqdm': 'tqdm:4.66.5', 'logical_cores': 8}\n",
      "[PARAMS] small n: [2, 3, 4] large n: [5, 8, 10, 15, 20, 30]\n",
      "[PARAMS] P_VALUES: [0.5, 0.9] D_VALUES: [2, 3, 4]\n",
      "[PATHS] RESULTS_DIR: outputs/results\n",
      "[CONST] PHI^2: 2.618033988749895\n",
      "n=2, p=0.0: C=0.0000, PoA=1.0000\n",
      "n=2, p=0.5: C=0.0625, PoA=1.6404\n",
      "n=2, p=1.0: C=0.2500, PoA=2.6180\n",
      "n=3, p=0.0: C=0.0000, PoA=1.0000\n",
      "n=3, p=0.5: C=0.0833, PoA=1.7676\n",
      "n=3, p=1.0: C=0.2500, PoA=2.6180\n",
      "n=10, p=0.0: C=0.0000, PoA=1.0000\n",
      "n=10, p=0.5: C=0.1736, PoA=2.2500\n",
      "n=10, p=1.0: C=0.2500, PoA=2.6180\n",
      "d=2, p=0.1: z_SV=1.0512, PoA_SV=1.1051 | z_PS=1.0512, PoA_PS=1.1051\n",
      "d=2, p=0.5: z_SV=1.2808, PoA_SV=1.6404 | z_PS=1.2808, PoA_PS=1.6404\n",
      "d=2, p=0.9: z_SV=1.5466, PoA_SV=2.3919 | z_PS=1.5466, PoA_PS=2.3919\n",
      "d=3, p=0.1: z_SV=1.1049, PoA_SV=1.3489 | z_PS=1.1031, PoA_PS=1.3423\n",
      "d=3, p=0.5: z_SV=1.6053, PoA_SV=4.1366 | z_PS=1.5558, PoA_PS=3.7662\n",
      "d=3, p=0.9: z_SV=2.1798, PoA_SV=10.3572 | z_PS=2.0296, PoA_PS=8.3607\n",
      "d=4, p=0.1: z_SV=1.1889, PoA_SV=1.9979 | z_PS=1.1795, PoA_PS=1.9353\n",
      "d=4, p=0.5: z_SV=2.0704, PoA_SV=18.3758 | z_PS=1.8766, PoA_PS=12.4015\n",
      "d=4, p=0.9: z_SV=2.9574, PoA_SV=76.4982 | z_PS=2.4871, PoA_PS=38.2623\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook 1: global imports, style, and reproducibility helpers ---\n",
    "# (safe to run multiple times)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import platform\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, Callable, Optional, Sequence\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # optional; used for nicer defaults in local Jupyter\n",
    "from scipy.optimize import root_scalar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility & paths\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "\n",
    "def set_global_seed(seed: int = 42):\n",
    "    \"\"\"Set seeds for numpy; return a Generator for downstream use.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "rng = set_global_seed(SEED)\n",
    "\n",
    "# Output directories\n",
    "PROJ_ROOT = Path.cwd()\n",
    "OUT_DIR = PROJ_ROOT / \"outputs\"\n",
    "FIG_DIR = OUT_DIR / \"figs\"\n",
    "TAB_DIR = OUT_DIR / \"tables\"\n",
    "for d in (OUT_DIR, FIG_DIR, TAB_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Matplotlib / pandas display\n",
    "# -----------------------------\n",
    "plt.style.use(\"seaborn-v0_8-ticks\")  # works with modern Matplotlib without seaborn installed\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (9, 6),\n",
    "    \"figure.dpi\": 120,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 13,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"legend.title_fontsize\": 12,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "})\n",
    "\n",
    "# Optional seaborn theme (keeps Matplotlib in control; comment out if undesired)\n",
    "sns.set_theme(context=\"notebook\", style=\"ticks\")\n",
    "\n",
    "# pandas display (nice for sanity checks; doesn't affect computations)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# -----------------------------\n",
    "# Small utilities: timing & env dump\n",
    "# -----------------------------\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.t0 = time.perf_counter()\n",
    "        return self\n",
    "    def __exit__(self, *exc):\n",
    "        self.elapsed = time.perf_counter() - self.t0\n",
    "\n",
    "\n",
    "def env_summary() -> dict:\n",
    "    import multiprocessing as mp\n",
    "    try:\n",
    "        import psutil  # optional\n",
    "        mem = getattr(psutil, \"virtual_memory\", lambda: None)()\n",
    "        mem_gb = None if mem is None else round(mem.total/1e9, 2)\n",
    "    except Exception:\n",
    "        mem_gb = None\n",
    "    return {\n",
    "        \"python\": sys.version.split(\" (\" )[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"cpu_count\": os.cpu_count(),\n",
    "        \"ram_gb\": mem_gb,\n",
    "        \"numpy\": np.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"matplotlib\": plt.matplotlib.__version__,\n",
    "        \"scipy\": root_scalar.__module__.split(\".\")[0] + \":\" + __import__(\"scipy\").__version__,\n",
    "        \"seaborn\": sns.__version__,\n",
    "        \"tqdm\": tqdm.__module__.split(\".\")[0] + \":\" + __import__(\"tqdm\").__version__,\n",
    "        \"logical_cores\": mp.cpu_count(),\n",
    "    }\n",
    "\n",
    "ENV_INFO = env_summary()\n",
    "print(\"[ENV]\", ENV_INFO)\n",
    "\n",
    "# Convenience RNG helper for modules that prefer Generator inputs\n",
    "random = rng  # alias for downstream code\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "from pathlib import Path\n",
    "OUT_DIR = Path(\"outputs\"); FIG_DIR = OUT_DIR/\"figs\"; TAB_DIR = OUT_DIR/\"tables\"\n",
    "for d in (OUT_DIR, FIG_DIR, TAB_DIR): d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "\n",
    "# === Simulation Parameters & Constants (Notebook 1) ===\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Small-scale exact analysis\n",
    "NUM_INSTANCES_SMALL: int = 10000   # exact enumeration budget (small n)\n",
    "N_VALUES_SMALL = [2, 3, 4]        # players for exact small-scale\n",
    "\n",
    "# Medium/large-scale sampling-based experiments\n",
    "NUM_INSTANCES_MEDIUM: int = 1000  # budget per (n, p, d, rule) combo\n",
    "N_VALUES_LARGE = [5, 8, 10, 15, 20, 30]\n",
    "\n",
    "# Key hyper-parameters\n",
    "P_VALUES = [0.5, 0.9]             # participation probabilities\n",
    "D_VALUES = [2, 3, 4]              # polynomial degree of c_e(x) = a x^d\n",
    "BRD_MAX_ITER = 1_000              # BRD iteration cap per restart\n",
    "BRD_RESTARTS = 10                 # multi-starts per instance\n",
    "EPS = 1e-9                        # float tolerance (equality / stopping)\n",
    "\n",
    "# Sanity checks (fail fast if typo)\n",
    "assert all(isinstance(n, int) and n >= 2 for n in N_VALUES_SMALL + N_VALUES_LARGE)\n",
    "assert all(0 < p <= 1 for p in P_VALUES)\n",
    "assert all(d >= 2 for d in D_VALUES)\n",
    "assert BRD_MAX_ITER > 0 and BRD_RESTARTS >= 1 and EPS > 0\n",
    "\n",
    "# Reproducible seeds per high-level sweep (optional but handy)\n",
    "SEED_GRID = {\n",
    "    \"small\": 20250101,\n",
    "    \"medium\": 20250102,\n",
    "    \"large\": 20250103,\n",
    "}\n",
    "\n",
    "# === Paths for artifacts ===\n",
    "RESULTS_DIR = OUT_DIR / \"results\"  # OUT_DIR defined in the setup cell\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Plotting style helpers ===\n",
    "COLORS = {\n",
    "    \"SV\": \"#0072B2\",    # Shapley Value - Blue\n",
    "    \"PS\": \"#D55E00\",    # Proportional Sharing - Burnt Orange\n",
    "    2: \"#0072B2\",\n",
    "    3: \"#D55E00\",\n",
    "    4: \"#009E73\",\n",
    "    10: \"#CC79A7\",\n",
    "    \"limit\": \"black\",\n",
    "}\n",
    "\n",
    "# Golden ratio constants\n",
    "PHI = (1 + np.sqrt(5)) / 2\n",
    "PHI_SQUARED = float(PHI ** 2)\n",
    "\n",
    "# Compact config dataclass (optional, used by generators)\n",
    "@dataclass(frozen=True)\n",
    "class RunConfig:\n",
    "    n: int\n",
    "    p: float\n",
    "    d: int\n",
    "    rule: str  # \"SV\" or \"PS\"\n",
    "    seed: int\n",
    "\n",
    "    def tag(self) -> str:\n",
    "        return f\"n{self.n}_p{self.p:g}_d{self.d}_{self.rule}_s{self.seed}\"\n",
    "\n",
    "print(\"[PARAMS] small n:\", N_VALUES_SMALL, \"large n:\", N_VALUES_LARGE)\n",
    "print(\"[PARAMS] P_VALUES:\", P_VALUES, \"D_VALUES:\", D_VALUES)\n",
    "print(\"[PATHS] RESULTS_DIR:\", RESULTS_DIR)\n",
    "print(\"[CONST] PHI^2:\", PHI_SQUARED)\n",
    "\n",
    "# === Theory bounds & root helpers ===\n",
    "# Robust, vector-friendly implementations for:\n",
    "#   - C_func_hom(p, n)\n",
    "#   - poa_hom_quadratic(p, n)\n",
    "#   - z_star_sv / poa_2player_sv\n",
    "#   - z_star_ps / poa_2player_ps\n",
    "# Notes:\n",
    "# * Accept both scalars and numpy arrays for p.\n",
    "# * Root-finding uses an expanding bracket to avoid ValueError from brentq.\n",
    "\n",
    "from typing import Union, Tuple, Callable\n",
    "import numpy as np\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "ArrayLike = Union[float, int, np.ndarray]\n",
    "\n",
    "# ---- small numeric helpers ----\n",
    "_EPS = EPS  # from params cell\n",
    "\n",
    "\n",
    "def _to_array(x: ArrayLike) -> np.ndarray:\n",
    "    \"\"\"Ensure numpy float array without modifying scalars' shape when possible.\"\"\"\n",
    "    return np.asarray(x, dtype=float)\n",
    "\n",
    "\n",
    "# ---- Homogeneous quadratic bound C(p,n) and PoA ----\n",
    "\n",
    "def C_func_hom(p: ArrayLike, n: int) -> ArrayLike:\n",
    "    \"\"\"C(p,n) from Theorem 1 (Homogeneous, Quadratic).\n",
    "    Accepts scalar or array p. Returns same shape as p.\n",
    "    For n < 2, returns NaN.\n",
    "    \"\"\"\n",
    "    p_arr = _to_array(p)\n",
    "    if n < 2:\n",
    "        return np.full(p_arr.shape, np.nan)\n",
    "    m1 = n // 2\n",
    "    m2 = n - m1\n",
    "    # (m1, m2) >= 1 since n>=2\n",
    "    numerator = p_arr**2\n",
    "    denom = 4.0 * (p_arr + (1.0 - p_arr) / m1) * (p_arr + (1.0 - p_arr) / m2)\n",
    "    out = np.empty_like(p_arr, dtype=float)\n",
    "    np.divide(numerator, denom, out=out, where=denom != 0)\n",
    "    return out if isinstance(p, np.ndarray) else float(out.item())\n",
    "\n",
    "\n",
    "def poa_hom_quadratic(p: ArrayLike, n: int) -> ArrayLike:\n",
    "    \"\"\"PoA upper bound from Theorem 1 (Homogeneous, Quadratic).\n",
    "    Vectorized in p; handles p=0 -> PoA=1.\n",
    "    \"\"\"\n",
    "    p_arr = _to_array(p)\n",
    "    C_val = C_func_hom(p_arr, n)\n",
    "    poa = (np.sqrt(C_val) + np.sqrt(C_val + 1.0))**2\n",
    "    # handle p==0 → 1 (even though typical runs use p>0)\n",
    "    if np.isscalar(p):\n",
    "        return 1.0 if abs(float(p)) <= _EPS else float(poa)\n",
    "    poa = np.where(np.abs(p_arr) <= _EPS, 1.0, poa)\n",
    "    return poa\n",
    "\n",
    "\n",
    "# ---- Root finding with expanding bracket ----\n",
    "\n",
    "def _bracket_then_brentq(f: Callable[[float], float],\n",
    "                         lo: float = 1e-12,\n",
    "                         hi0: float = 1.0,\n",
    "                         max_hi: float = 1e8,\n",
    "                         max_doubles: int = 60) -> Tuple[bool, float]:\n",
    "    \"\"\"Find a bracketing interval [lo, hi] with sign change, expanding hi exponentially;\n",
    "    then run brentq. Returns (ok, root_or_nan).\n",
    "    Assumes f(lo) > 0 and f(hi) eventually < 0 for our use cases.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        flo = f(lo)\n",
    "    except Exception:\n",
    "        return False, np.nan\n",
    "    hi = hi0\n",
    "    for _ in range(max_doubles):\n",
    "        try:\n",
    "            fhi = f(hi)\n",
    "        except Exception:\n",
    "            return False, np.nan\n",
    "        if np.isnan(flo) or np.isnan(fhi):\n",
    "            return False, np.nan\n",
    "        if flo * fhi < 0:  # bracket found\n",
    "            try:\n",
    "                sol = root_scalar(f, bracket=[lo, hi], method=\"brentq\")\n",
    "                return (sol.converged, sol.root if sol.converged else np.nan)\n",
    "            except Exception:\n",
    "                return False, np.nan\n",
    "        hi *= 2.0\n",
    "        if hi > max_hi:\n",
    "            break\n",
    "    return False, np.nan\n",
    "\n",
    "\n",
    "# ---- 2-player SV ----\n",
    "\n",
    "def z_star_sv(p: float, d: int) -> float:\n",
    "    \"\"\"Root z*>0 for 2-player SV (Theorem 7):\n",
    "        (1 - p/2) + (p/2)*(1+z)^d - (1 + p/2)*z^d = 0\n",
    "       For p≈0 → 1, return z*=1.\n",
    "    \"\"\"\n",
    "    p = float(p)\n",
    "    if p <= _EPS:\n",
    "        return 1.0\n",
    "    def f(z: float) -> float:\n",
    "        return (1.0 - p/2.0) + (p/2.0)*(1.0 + z)**d - (1.0 + p/2.0)*z**d\n",
    "    ok, root = _bracket_then_brentq(f, lo=1e-12, hi0=1.0)\n",
    "    return float(root) if ok else np.nan\n",
    "\n",
    "\n",
    "def poa_2player_sv(p: float, d: int) -> float:\n",
    "    z = z_star_sv(p, d)\n",
    "    return float(z**d) if np.isfinite(z) else np.nan\n",
    "\n",
    "\n",
    "# ---- 2-player PS ----\n",
    "\n",
    "def z_star_ps(p: float, d: int) -> float:\n",
    "    \"\"\"Root z*>0 for 2-player PS (Theorem 9):\n",
    "        (1 - p) + p*(1+z)^{d-1} - z^d = 0\n",
    "       For d=2, identical to SV; for p≈0 → 1.\n",
    "    \"\"\"\n",
    "    p = float(p)\n",
    "    if p <= _EPS:\n",
    "        return 1.0\n",
    "    if d == 2:\n",
    "        return z_star_sv(p, d)\n",
    "    def f(z: float) -> float:\n",
    "        return (1.0 - p) + p*(1.0 + z)**(d - 1) - z**d\n",
    "    ok, root = _bracket_then_brentq(f, lo=1e-12, hi0=1.0)\n",
    "    return float(root) if ok else np.nan\n",
    "\n",
    "\n",
    "def poa_2player_ps(p: float, d: int) -> float:\n",
    "    z = z_star_ps(p, d)\n",
    "    return float(z**d) if np.isfinite(z) else np.nan\n",
    "\n",
    "\n",
    "# ---- Quick sanity checks ----\n",
    "if __name__ == \"__main__\":\n",
    "    for n in (2, 3, 10):\n",
    "        for p in (0.0, 0.5, 1.0):\n",
    "            C = C_func_hom(p, n)\n",
    "            PoA = poa_hom_quadratic(p, n)\n",
    "            print(f\"n={n}, p={p}: C={C:.4f}, PoA={PoA:.4f}\")\n",
    "    for d in (2, 3, 4):\n",
    "        for p in (0.1, 0.5, 0.9):\n",
    "            zsv = z_star_sv(p, d); psv = poa_2player_sv(p, d)\n",
    "            zps = z_star_ps(p, d); pps = poa_2player_ps(p, d)\n",
    "            print(f\"d={d}, p={p}: z_SV={zsv:.4f}, PoA_SV={psv:.4f} | z_PS={zps:.4f}, PoA_PS={pps:.4f}\")\n",
    "\n",
    "# ================================================================\n",
    "# Part 1: Instance Generation & Exact Cost Calculation (with Exact SV)\n",
    "# ================================================================\n",
    "from __future__ import annotations\n",
    "import itertools\n",
    "from typing import Dict, Tuple, List, Any\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# 全局容差（与主 Notebook 保持一致）\n",
    "try:\n",
    "    EPS = EPS  # noqa: F821  # 若上文已定义则沿用\n",
    "except Exception:\n",
    "    EPS = 1e-9\n",
    "\n",
    "# ------------------------------\n",
    "# 随机实例生成（去重 & 可复现）\n",
    "# ------------------------------\n",
    "\n",
    "def generate_random_instance(\n",
    "    n: int,\n",
    "    num_strategies_per_player: int,\n",
    "    num_resources: int,\n",
    "    rng: np.random.Generator,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    生成一个随机博弈实例。\n",
    "    - 为每个玩家生成若干条不重复路径（随机子集），避免重复策略。\n",
    "    - 权重 w_i ~ U[0.5, 2.0]\n",
    "    - 边系数 a_e ~ U[0.5, 1.5]\n",
    "    \"\"\"\n",
    "    instance = {\n",
    "        'n': n,\n",
    "        'num_resources': num_resources,\n",
    "        'num_strategies_per_player': num_strategies_per_player,\n",
    "        'weights': rng.uniform(0.5, 10.0, size=n),\n",
    "        'a_coeffs': rng.uniform(0.5, 3, size=num_resources),\n",
    "        'strategies': []  # List[List[Tuple[int, ...]]]\n",
    "    }\n",
    "    resources = list(range(num_resources))\n",
    "    for _ in range(n):\n",
    "        player_strategies: List[Tuple[int, ...]] = []\n",
    "        seen = set()\n",
    "        # 尽量生成去重的路径；若资源很少且策略数很多，可能出现生成困难，此处简单重试若干次\n",
    "        trials = 0\n",
    "        while len(player_strategies) < num_strategies_per_player and trials < 10_000:\n",
    "            trials += 1\n",
    "            k = int(rng.integers(1, num_resources + 1))\n",
    "            path = tuple(sorted(rng.choice(resources, size=k, replace=False)))\n",
    "            if path not in seen:\n",
    "                seen.add(path)\n",
    "                player_strategies.append(path)\n",
    "        if len(player_strategies) < num_strategies_per_player:\n",
    "            # 退而求其次：若极端情况下仍不足，重复最后一个（保持维度一致）\n",
    "            while len(player_strategies) < num_strategies_per_player:\n",
    "                player_strategies.append(player_strategies[-1])\n",
    "        instance['strategies'].append(player_strategies)\n",
    "    return instance\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 精确成本计算：枚举 2^n 类型 + 精确 SV（d>2 为排列法）\n",
    "# ----------------------------------------------\n",
    "\n",
    "def calculate_exact_costs(\n",
    "    instance: Dict[str, Any],\n",
    "    profile: Tuple[int, ...],\n",
    "    p: float,\n",
    "    d: int,\n",
    "    rule: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    计算无条件期望成本（玩家成本向量 + 社会成本）。\n",
    "    - rule='PS': 比例分摊\n",
    "    - rule='SV': Shapley 值（d=2 用闭式，d>2 用排列精确计算）\n",
    "    仅用于小规模 n（例如 ≤4）的穷举分析。\n",
    "    \"\"\"\n",
    "    rule = rule.upper()\n",
    "    if rule not in {\"PS\", \"SV\"}:\n",
    "        raise ValueError(f\"Unknown rule '{rule}'. Use 'PS' or 'SV'.\")\n",
    "\n",
    "    n = instance['n']\n",
    "    weights: np.ndarray = np.asarray(instance['weights'], dtype=float)\n",
    "    a_coeffs: np.ndarray = np.asarray(instance['a_coeffs'], dtype=float)\n",
    "    num_resources = int(instance['num_resources'])\n",
    "\n",
    "    # 固定策略剖面对应的路径（每个玩家选一条）\n",
    "    strategies: List[List[Tuple[int, ...]]] = instance['strategies']\n",
    "    player_paths: Tuple[Tuple[int, ...], ...] = tuple(\n",
    "        strategies[i][profile[i]] for i in range(n)\n",
    "    )\n",
    "\n",
    "    # 预计算：每条边在该 profile 下的潜在使用者集合（提升一点点性能）\n",
    "    users_by_edge: List[set[int]] = []\n",
    "    for e in range(num_resources):\n",
    "        users = {i for i in range(n) if e in player_paths[i]}\n",
    "        users_by_edge.append(users)\n",
    "\n",
    "    total_expected_player_costs = np.zeros(n, dtype=float)\n",
    "\n",
    "    # 穷举 2^n 类型向量\n",
    "    for mask in range(1 << n):\n",
    "        # types[j] ∈ {0,1}\n",
    "        types = [(mask >> j) & 1 for j in range(n)]\n",
    "        # 概率（同质 p）\n",
    "        prob = 1.0\n",
    "        for t in types:\n",
    "            prob *= (p if t == 1 else (1 - p))\n",
    "        if prob < 1e-16:\n",
    "            continue\n",
    "\n",
    "        active_players = {idx for idx, t in enumerate(types) if t == 1}\n",
    "        if not active_players:\n",
    "            continue  # 无活跃玩家则所有边分摊为 0\n",
    "\n",
    "        for e in range(num_resources):\n",
    "            if not users_by_edge[e]:\n",
    "                continue  # 该 profile 下无人选择此边\n",
    "\n",
    "            active_on_edge = active_players & users_by_edge[e]\n",
    "            if not active_on_edge:\n",
    "                continue\n",
    "\n",
    "            a_e = a_coeffs[e]\n",
    "\n",
    "            if rule == 'PS':\n",
    "                total_w = float(np.sum(weights[list(active_on_edge)]))\n",
    "                if total_w <= 0:\n",
    "                    continue\n",
    "                edge_cost = a_e * (total_w ** d)\n",
    "                for i in active_on_edge:\n",
    "                    share = edge_cost * (weights[i] / total_w)\n",
    "                    total_expected_player_costs[i] += prob * share\n",
    "\n",
    "            else:  # 'SV'\n",
    "                if d == 2:\n",
    "                    # 闭式：chi_i = a_e * w_i * W\n",
    "                    total_w = float(np.sum(weights[list(active_on_edge)]))\n",
    "                    for i in active_on_edge:\n",
    "                        share = a_e * weights[i] * total_w\n",
    "                        total_expected_player_costs[i] += prob * share\n",
    "                else:\n",
    "                    # 精确排列（|S|!），仅用于小 n\n",
    "                    players_on_edge = list(active_on_edge)\n",
    "                    m = len(players_on_edge)\n",
    "                    if m == 1:\n",
    "                        # 只有自己时，SV = c(w_i)\n",
    "                        i = players_on_edge[0]\n",
    "                        share = a_e * (weights[i] ** d)\n",
    "                        total_expected_player_costs[i] += prob * share\n",
    "                    else:\n",
    "                        fact_m = math.factorial(m)\n",
    "                        for i in players_on_edge:\n",
    "                            total_mc = 0.0\n",
    "                            w_i = float(weights[i])\n",
    "                            for perm in itertools.permutations(players_on_edge):\n",
    "                                # i 的前置集合的总权重\n",
    "                                idx_i = perm.index(i)\n",
    "                                if idx_i == 0:\n",
    "                                    w_pred = 0.0\n",
    "                                else:\n",
    "                                    w_pred = float(np.sum([weights[j] for j in perm[:idx_i]]))\n",
    "                                total_mc += a_e * ((w_pred + w_i) ** d - (w_pred) ** d)\n",
    "                            share = total_mc / fact_m\n",
    "                            total_expected_player_costs[i] += prob * share\n",
    "\n",
    "    social_cost = float(np.sum(total_expected_player_costs))\n",
    "    return {'player_costs': total_expected_player_costs, 'social_cost': social_cost}\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Part 2: 单实例分析（检查 BNE 并返回非平凡 PoA 的 max/avg）\n",
    "# ======================================================================\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def run_small_scale_analysis_for_instance(\n",
    "    instance: Dict[str, Any],\n",
    "    p: float,\n",
    "    d: int,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    穷举 profile，计算 PS 与 SV（精确）下的 BNE，并输出非平凡 PoA 的 max / avg。\n",
    "    注意：此函数假设同质概率 p；若需要异质 p_i，请扩展 calculate_exact_costs。\n",
    "    \"\"\"\n",
    "    n = int(instance['n'])\n",
    "    num_strats = int(instance['num_strategies_per_player'])\n",
    "    all_profiles = list(product(range(num_strats), repeat=n))\n",
    "\n",
    "    # 预计算所有 profile 成本（避免重复调用）\n",
    "    profile_costs_ps: Dict[Tuple[int, ...], Dict[str, Any]] = {}\n",
    "    profile_costs_sv: Dict[Tuple[int, ...], Dict[str, Any]] = {}\n",
    "    for prof in all_profiles:\n",
    "        profile_costs_ps[prof] = calculate_exact_costs(instance, prof, p, d, 'PS')\n",
    "        profile_costs_sv[prof] = calculate_exact_costs(instance, prof, p, d, 'SV')\n",
    "\n",
    "    opt_ps = min(res['social_cost'] for res in profile_costs_ps.values()) if profile_costs_ps else math.inf\n",
    "    opt_sv = min(res['social_cost'] for res in profile_costs_sv.values()) if profile_costs_sv else math.inf\n",
    "\n",
    "    bne_poas_ps: List[float] = []\n",
    "    bne_poas_sv: List[float] = []\n",
    "\n",
    "    for prof in all_profiles:\n",
    "        # PS: 检查是否为 BNE（允许等价收益，加入 EPS 容忍）\n",
    "        is_bne_ps = True\n",
    "        costs_here_ps = profile_costs_ps[prof]['player_costs']\n",
    "        for i in range(n):\n",
    "            s_curr = prof[i]\n",
    "            best = costs_here_ps[i]\n",
    "            for s_alt in range(num_strats):\n",
    "                if s_alt == s_curr:\n",
    "                    continue\n",
    "                prof_alt = list(prof)\n",
    "                prof_alt[i] = s_alt\n",
    "                alt = profile_costs_ps[tuple(prof_alt)]['player_costs'][i]\n",
    "                if alt + EPS < best:\n",
    "                    is_bne_ps = False\n",
    "                    break\n",
    "            if not is_bne_ps:\n",
    "                break\n",
    "        if is_bne_ps and opt_ps > EPS:\n",
    "            bne_poas_ps.append(profile_costs_ps[prof]['social_cost'] / opt_ps)\n",
    "\n",
    "        # SV: 同理\n",
    "        is_bne_sv = True\n",
    "        costs_here_sv = profile_costs_sv[prof]['player_costs']\n",
    "        for i in range(n):\n",
    "            s_curr = prof[i]\n",
    "            best = costs_here_sv[i]\n",
    "            for s_alt in range(num_strats):\n",
    "                if s_alt == s_curr:\n",
    "                    continue\n",
    "                prof_alt = list(prof)\n",
    "                prof_alt[i] = s_alt\n",
    "                alt = profile_costs_sv[tuple(prof_alt)]['player_costs'][i]\n",
    "                if alt + EPS < best:\n",
    "                    is_bne_sv = False\n",
    "                    break\n",
    "            if not is_bne_sv:\n",
    "                break\n",
    "        if is_bne_sv and opt_sv > EPS:\n",
    "            bne_poas_sv.append(profile_costs_sv[prof]['social_cost'] / opt_sv)\n",
    "\n",
    "    nontrivial_ps = [x for x in bne_poas_ps if x > 1 + EPS]\n",
    "    nontrivial_sv = [x for x in bne_poas_sv if x > 1 + EPS]\n",
    "\n",
    "    return {\n",
    "        'max_poa_ps': (max(nontrivial_ps) if nontrivial_ps else float('nan')),\n",
    "        'avg_poa_ps': (float(np.mean(nontrivial_ps)) if nontrivial_ps else float('nan')),\n",
    "        'max_poa_sv': (max(nontrivial_sv) if nontrivial_sv else float('nan')),\n",
    "        'avg_poa_sv': (float(np.mean(nontrivial_sv)) if nontrivial_sv else float('nan')),\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Part 3: 小规模主实验（缓存文件名改为 exactSV 以示区分）\n",
    "# ======================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "RESULTS_DIR = Path('results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def run_small_scale_experiment(\n",
    "    n: int,\n",
    "    p: float,\n",
    "    d: int,\n",
    "    num_instances_target: int,\n",
    "    force_rerun: bool = False,\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    运行小规模穷举实验：累计到指定数量的“有效”实例（至少一个非平凡 PoA 的 BNE）后停止。\n",
    "    结果缓存为 CSV。\n",
    "    \"\"\"\n",
    "    fname = RESULTS_DIR / f\"small_scale_n{n}_p{int(round(p*100))}_d{d}_exactSV.csv\"\n",
    "    if fname.exists() and not force_rerun:\n",
    "        print(f\"Loading cached results from {fname} ...\")\n",
    "        return pd.read_csv(fname)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    results: List[Dict[str, float]] = []\n",
    "    pbar = tqdm(total=num_instances_target, desc=f\"Small-scale n={n}, p={p}, d={d}\")\n",
    "    total_runs = 0\n",
    "\n",
    "    while len(results) < num_instances_target:\n",
    "        total_runs += 1\n",
    "        inst = generate_random_instance(\n",
    "            n=n, num_strategies_per_player=2, num_resources=3, rng=rng\n",
    "        )\n",
    "        res = run_small_scale_analysis_for_instance(inst, p, d)\n",
    "        is_valid = (not np.isnan(res['max_poa_ps'])) or (not np.isnan(res['max_poa_sv']))\n",
    "        if is_valid:\n",
    "            results.append({'n': n, 'p': p, 'd': d, **res})\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    print(f\"Finished. Generated {total_runs} instances to obtain {num_instances_target} valid ones.\")\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(fname, index=False)\n",
    "    print(f\"Saved to {fname}\")\n",
    "    return df\n",
    "\n",
    "# Seed-safe orchestrator for small-scale grid\n",
    "# - Provides independent or paired instance sampling across (n, p, d)\n",
    "# - Drop-in replacement for your previous run_small_scale_grid_and_tightness\n",
    "\n",
    "import numpy as np\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "\n",
    "# assumes the following are already defined in your notebook:\n",
    "#   RESULTS_DIR, build_tightness_table, capture_env_info, run_small_scale_experiment\n",
    "#   N_VALUES_SMALL, P_VALUES, D_VALUES\n",
    "\n",
    "RESULTS_DIR = OUT_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def bootstrap_stat(values: np.ndarray,\n",
    "                   stat_fn: Callable[[np.ndarray], float],\n",
    "                   B: int = 2000,\n",
    "                   alpha: float = 0.05,\n",
    "                   seed: int = 1234) -> dict:\n",
    "    \"\"\"Nonparametric bootstrap for a scalar statistic.\n",
    "    Returns: dict(mean=..., ci_low=..., ci_high=..., samples=[...]).\n",
    "    Notes:\n",
    "      - NaN values are removed. If <2 valid samples: returns point estimate, CI=NaN.\n",
    "      - For 'max' statistic we just apply stat_fn to each resample (size=n with replacement).\n",
    "    \"\"\"\n",
    "    vals = np.asarray(values, dtype=float)\n",
    "    vals = vals[~np.isnan(vals)]\n",
    "    n = len(vals)\n",
    "    if n == 0:\n",
    "        return {\"mean\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan, \"samples\": []}\n",
    "\n",
    "    # If only one valid sample, CI is undefined under resampling-with-replacement\n",
    "    if n == 1:\n",
    "        est = float(stat_fn(vals))\n",
    "        return {\"mean\": est, \"ci_low\": np.nan, \"ci_high\": np.nan, \"samples\": [est]}\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    boots = np.empty(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        sample = vals[idx]\n",
    "        boots[b] = float(stat_fn(sample))\n",
    "    lo = float(np.quantile(boots, alpha/2))\n",
    "    hi = float(np.quantile(boots, 1 - alpha/2))\n",
    "    return {\"mean\": float(np.mean(boots)), \"ci_low\": lo, \"ci_high\": hi, \"samples\": boots}\n",
    "\n",
    "# --- Helper: theoretical bounds dispatcher ---\n",
    "def theoretical_bound(rule: str, n: int, p: float, d: int) -> Optional[float]:\n",
    "    \"\"\"Return the theoretical PoA upper bound for (rule, n, p, d) when available.\n",
    "    Rules:\n",
    "      - d == 2: use homogeneous quadratic bound for both SV and PS (they coincide).\n",
    "      - n == 2 and d >= 2: use the closed forms from the 2-player theorems.\n",
    "      - Otherwise: return np.nan (not available in this notebook's exact-analysis scope).\n",
    "    \"\"\"\n",
    "    rule = str(rule).upper()\n",
    "    if d == 2:\n",
    "        # Homogeneous quadratic bound (Theorem 1). Both rules same.\n",
    "        return float(poa_hom_quadratic(p, n))\n",
    "    if n == 2:\n",
    "        if rule == 'SV':\n",
    "            return float(poa_2player_sv(p, d))\n",
    "        if rule == 'PS':\n",
    "            return float(poa_2player_ps(p, d))\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def capture_env_info() -> dict:\n",
    "    return {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"numpy\": np.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"scipy\": __import__('scipy').__version__,\n",
    "        \"matplotlib\": mpl.__version__,\n",
    "        \"seaborn\": sns.__version__,\n",
    "        \"platform\": platform.platform(),\n",
    "        \"processor\": platform.processor(),\n",
    "        \"machine\": platform.machine(),\n",
    "    }\n",
    "    # if psutil is not None:\n",
    "    #     try:\n",
    "    #         vm = psutil.virtual_memory()\n",
    "    #         info.update({\n",
    "    #             \"ram_total_gb\": round(vm.total / (1024**3), 2),\n",
    "    #             \"ram_available_gb\": round(vm.available / (1024**3), 2),\n",
    "    #         })\n",
    "    #     except Exception:\n",
    "    #         pass\n",
    "    return info\n",
    "\n",
    "# --- Build tightness table from per-instance summaries ---\n",
    "def build_tightness_table(df_list: Sequence[pd.DataFrame],\n",
    "                          alpha: float = 0.05,\n",
    "                          B: int = 2000,\n",
    "                          seed: int = 2025) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate multiple cached per-instance CSVs into a tightness table.\n",
    "    Each input df has rows: {n, p, d, max_poa_ps, avg_poa_ps, max_poa_sv, avg_poa_sv} per instance.\n",
    "    We aggregate by (graph_class, n, p, d, rule) and report:\n",
    "      - observed_max, CI\n",
    "      - observed_avg, CI\n",
    "      - theoretical_upper_bound\n",
    "      - gap_to_bound (for max & avg)\n",
    "      - counts and NaN ratios\n",
    "    \"\"\"\n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    # For this notebook, small-scale generator is path-based random; mark graph class accordingly\n",
    "    df_all['graph_class'] = 'random-paths'\n",
    "\n",
    "    rows = []\n",
    "    keys = sorted(set(zip(df_all['graph_class'], df_all['n'], df_all['p'], df_all['d'])))\n",
    "    for (gcls, n, p, d) in keys:\n",
    "        sub = df_all[(df_all['graph_class']==gcls)&(df_all['n']==n)&(df_all['p']==p)&(df_all['d']==d)]\n",
    "        for rule, col_max, col_avg in [('PS','max_poa_ps','avg_poa_ps'), ('SV','max_poa_sv','avg_poa_sv')]:\n",
    "            vals_max = sub[col_max].to_numpy(dtype=float)\n",
    "            vals_avg = sub[col_avg].to_numpy(dtype=float)\n",
    "            # Observed statistics\n",
    "            obs_max = np.nanmax(vals_max) if np.any(~np.isnan(vals_max)) else np.nan\n",
    "            obs_avg = np.nanmean(vals_avg) if np.any(~np.isnan(vals_avg)) else np.nan\n",
    "            # Bootstrap CIs (deterministic via seed)\n",
    "            ci_max = bootstrap_stat(vals_max, np.nanmax, B=B, alpha=alpha, seed=seed)\n",
    "            ci_avg = bootstrap_stat(vals_avg, np.nanmean, B=B, alpha=alpha, seed=seed+1)\n",
    "            # Theory bound\n",
    "            bound = theoretical_bound(rule, int(n), float(p), int(d))\n",
    "            # Gaps\n",
    "            gap_max = (bound - obs_max) if (not np.isnan(bound) and not np.isnan(obs_max)) else np.nan\n",
    "            gap_avg = (bound - obs_avg) if (not np.isnan(bound) and not np.isnan(obs_avg)) else np.nan\n",
    "            rows.append({\n",
    "                'graph': gcls,\n",
    "                'n': int(n), 'p': float(p), 'd': int(d), 'Rule': rule,\n",
    "                'observed_max_poa': obs_max,\n",
    "                'max_ci_low': ci_max['ci_low'], 'max_ci_high': ci_max['ci_high'],\n",
    "                'observed_avg_poa': obs_avg,\n",
    "                'avg_ci_low': ci_avg['ci_low'], 'avg_ci_high': ci_avg['ci_high'],\n",
    "                'theory_bound': bound,\n",
    "                'gap_to_bound_max': gap_max,\n",
    "                'gap_to_bound_avg': gap_avg,\n",
    "                'count': int(len(sub)),\n",
    "                'nan_frac_max': float(np.mean(np.isnan(vals_max))) if len(vals_max)>0 else np.nan,\n",
    "                'nan_frac_avg': float(np.mean(np.isnan(vals_avg))) if len(vals_avg)>0 else np.nan,\n",
    "            })\n",
    "    tight = pd.DataFrame(rows)\n",
    "    # canonical ordering for downstream table formatting\n",
    "    tight = tight.sort_values([\"graph\",\"p\",\"n\",\"d\",\"Rule\"]).reset_index(drop=True)\n",
    "    return tight\n",
    "\n",
    "def _derive_cfg_seed(base_seed: int, n: int, p: float, d: int, independent: bool = True) -> int:\n",
    "    \"\"\"Derive a deterministic 32-bit seed for a config.\n",
    "    - independent=True: unique seed for each (n,p,d)\n",
    "    - independent=False: same seed for all configs sharing n (paired comparison across p,d)\n",
    "    Using SeedSequence keeps it portable and reproducible.\n",
    "    \"\"\"\n",
    "    # quantize p to avoid float representation wobble in the key\n",
    "    p_key = int(round(float(p) * 1_000_000)) if independent else 0\n",
    "    d_key = int(d) if independent else 0\n",
    "    ss = np.random.SeedSequence([int(base_seed), int(n), int(p_key), int(d_key)])\n",
    "    return int(ss.generate_state(1, dtype=np.uint32)[0])\n",
    "\n",
    "\n",
    "\n",
    "def run_small_scale_grid_and_tightness(\n",
    "    n_values=N_VALUES_SMALL,\n",
    "    p_values=P_VALUES,\n",
    "    d_values=D_VALUES,\n",
    "    instances_each: int = 200,\n",
    "    force_rerun: bool = False,\n",
    "    base_seed: int = 42,\n",
    "    independent_instances: bool = True,\n",
    "    alpha: float = 0.05,\n",
    "    B: int = 2000,\n",
    "):\n",
    "    \"\"\"Run the grid of small-scale experiments with seed safety.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    independent_instances : bool\n",
    "        - True  -> each (n,p,d) gets an independent RNG seed (statistically independent).\n",
    "        - False -> all configs that share the same n reuse the *same* instance pool\n",
    "                   (paired comparisons across p,d; useful to reduce variance when comparing settings).\n",
    "    base_seed : int\n",
    "        Master seed from which per-config seeds are deterministically derived.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    dfs = []\n",
    "\n",
    "    # Collect per-config seeds for auditability\n",
    "    seed_book = []\n",
    "\n",
    "    for n in n_values:\n",
    "        for p in p_values:\n",
    "            for d in d_values:\n",
    "                cfg_seed = _derive_cfg_seed(base_seed, int(n), float(p), int(d), independent=independent_instances)\n",
    "                seed_book.append({\"n\": int(n), \"p\": float(p), \"d\": int(d), \"seed\": int(cfg_seed)})\n",
    "\n",
    "                df = run_small_scale_experiment(\n",
    "                    n=int(n), p=float(p), d=int(d),\n",
    "                    num_instances_target=int(instances_each),\n",
    "                    force_rerun=force_rerun,\n",
    "                    seed=int(cfg_seed),\n",
    "                )\n",
    "                dfs.append(df)\n",
    "\n",
    "    # Tightness table\n",
    "    tight = build_tightness_table(dfs, alpha=alpha, B=B, seed=base_seed + 7)\n",
    "\n",
    "    # Save artifacts\n",
    "    env = capture_env_info()\n",
    "    tight_path = RESULTS_DIR / 'tightness_small_scale.csv'\n",
    "    env_path = RESULTS_DIR / 'env_small_scale.json'\n",
    "    seeds_path = RESULTS_DIR / 'seeds_small_scale.json'\n",
    "    tight.to_csv(tight_path, index=False)\n",
    "    with open(env_path, 'w') as f:\n",
    "        json.dump(env, f, indent=2)\n",
    "    with open(seeds_path, 'w') as f:\n",
    "        json.dump(seed_book, f, indent=2)\n",
    "\n",
    "    print(f\"Saved tightness table -> {tight_path}\")\n",
    "    print(f\"Saved environment specs -> {env_path}\")\n",
    "    print(f\"Saved per-config seeds -> {seeds_path}\")\n",
    "    print(f\"Total wall-clock: {time.time() - t0:.1f}s\")\n",
    "\n",
    "    return tight\n",
    "\n",
    "# Usage examples (pick one):\n",
    "# 1) Independent sampling across the whole grid (recommended for unbiased distributional summaries)\n",
    "# tight = run_small_scale_grid_and_tightness(independent_instances=True)\n",
    "# 2) Paired sampling across p,d within each n (same instance pool per n; good for fair A/B comparisons)\n",
    "# tight = run_small_scale_grid_and_tightness(independent_instances=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac10105e7f184ee8b7011a01c7cb040a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.5, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 300508 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p50_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd5017159404d7f9a12dd231820d6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.5, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 304016 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p50_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9782e17c36b4deab7a3574b9366aad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.5, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 318732 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p50_d4_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff2850bf9af4442924e5964eb3f19db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.9, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 279314 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p90_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc95608373464e64a34321b2c6c2de97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.9, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 306246 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p90_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29eb2c274644733a56c66374b9c5261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=2, p=0.9, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 304900 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n2_p90_d4_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d97de89a254957a77307a930a2cc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.5, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 200586 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p50_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d7fd3bd7c34da6915e8427eb843724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.5, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 191385 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p50_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343af8913c5349dfafdff2bc4601cb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.5, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 193822 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p50_d4_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ddb20a1f0a440d89b8f523f1cd958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.9, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 193363 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p90_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09707925ee445329470318bdc4192ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.9, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 189261 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p90_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29391a379954f719c51d65c72051301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=3, p=0.9, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 191439 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n3_p90_d4_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddad7e74d1e14404a74f6f51cd6cf5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.5, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 160655 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p50_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27f1cb9594944e4abf8f5b30b9bee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.5, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 145002 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p50_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b709919fa1641a5bc714ad671b9d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.5, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 137675 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p50_d4_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaadf1271d74a1785e08050db7baca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.9, d=2:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 163469 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p90_d2_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42db56818f0949d2b72e20a21cd4a7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.9, d=3:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 139440 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p90_d3_exactSV.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf8a12ac7704f6e94a685a0fa95c950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Small-scale n=4, p=0.9, d=4:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Generated 132781 instances to obtain 10000 valid ones.\n",
      "Saved to outputs/results/small_scale_n4_p90_d4_exactSV.csv\n",
      "Saved tightness table -> outputs/results/tightness_small_scale.csv\n",
      "Saved environment specs -> outputs/results/env_small_scale.json\n",
      "Saved per-config seeds -> outputs/results/seeds_small_scale.json\n",
      "Total wall-clock: 5810.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>d</th>\n",
       "      <th>Rule</th>\n",
       "      <th>observed_max_poa</th>\n",
       "      <th>max_ci_low</th>\n",
       "      <th>max_ci_high</th>\n",
       "      <th>observed_avg_poa</th>\n",
       "      <th>avg_ci_low</th>\n",
       "      <th>avg_ci_high</th>\n",
       "      <th>theory_bound</th>\n",
       "      <th>gap_to_bound_max</th>\n",
       "      <th>gap_to_bound_avg</th>\n",
       "      <th>count</th>\n",
       "      <th>nan_frac_max</th>\n",
       "      <th>nan_frac_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-paths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>PS</td>\n",
       "      <td>1.489209</td>\n",
       "      <td>1.445080</td>\n",
       "      <td>1.489209</td>\n",
       "      <td>1.068891</td>\n",
       "      <td>1.067704</td>\n",
       "      <td>1.070057</td>\n",
       "      <td>1.640388</td>\n",
       "      <td>0.151179</td>\n",
       "      <td>0.571498</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random-paths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>SV</td>\n",
       "      <td>1.489209</td>\n",
       "      <td>1.445080</td>\n",
       "      <td>1.489209</td>\n",
       "      <td>1.068891</td>\n",
       "      <td>1.067704</td>\n",
       "      <td>1.070057</td>\n",
       "      <td>1.640388</td>\n",
       "      <td>0.151179</td>\n",
       "      <td>0.571498</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random-paths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>PS</td>\n",
       "      <td>2.414634</td>\n",
       "      <td>2.382862</td>\n",
       "      <td>2.414634</td>\n",
       "      <td>1.181701</td>\n",
       "      <td>1.178014</td>\n",
       "      <td>1.185743</td>\n",
       "      <td>3.766177</td>\n",
       "      <td>1.351543</td>\n",
       "      <td>2.584476</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random-paths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>SV</td>\n",
       "      <td>2.414634</td>\n",
       "      <td>2.353706</td>\n",
       "      <td>2.414634</td>\n",
       "      <td>1.177918</td>\n",
       "      <td>1.174267</td>\n",
       "      <td>1.181675</td>\n",
       "      <td>4.136631</td>\n",
       "      <td>1.721997</td>\n",
       "      <td>2.958714</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random-paths</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>PS</td>\n",
       "      <td>4.422150</td>\n",
       "      <td>4.206269</td>\n",
       "      <td>4.422150</td>\n",
       "      <td>1.371484</td>\n",
       "      <td>1.361445</td>\n",
       "      <td>1.381472</td>\n",
       "      <td>12.401529</td>\n",
       "      <td>7.979379</td>\n",
       "      <td>11.030044</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.0939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          graph  n    p  d Rule  observed_max_poa  max_ci_low  max_ci_high  observed_avg_poa  avg_ci_low  avg_ci_high  theory_bound  gap_to_bound_max  \\\n",
       "0  random-paths  2  0.5  2   PS          1.489209    1.445080     1.489209          1.068891    1.067704     1.070057      1.640388          0.151179   \n",
       "1  random-paths  2  0.5  2   SV          1.489209    1.445080     1.489209          1.068891    1.067704     1.070057      1.640388          0.151179   \n",
       "2  random-paths  2  0.5  3   PS          2.414634    2.382862     2.414634          1.181701    1.178014     1.185743      3.766177          1.351543   \n",
       "3  random-paths  2  0.5  3   SV          2.414634    2.353706     2.414634          1.177918    1.174267     1.181675      4.136631          1.721997   \n",
       "4  random-paths  2  0.5  4   PS          4.422150    4.206269     4.422150          1.371484    1.361445     1.381472     12.401529          7.979379   \n",
       "\n",
       "   gap_to_bound_avg  count  nan_frac_max  nan_frac_avg  \n",
       "0          0.571498  10000        0.0000        0.0000  \n",
       "1          0.571498  10000        0.0000        0.0000  \n",
       "2          2.584476  10000        0.0542        0.0542  \n",
       "3          2.958714  10000        0.0398        0.0398  \n",
       "4         11.030044  10000        0.0939        0.0939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl # <<< FIX: Added the required import\n",
    "# Example usage in a separate cell (keep heavy runs explicit):\n",
    "tight = run_small_scale_grid_and_tightness(instances_each=10000, force_rerun=True, independent_instances=False)\n",
    "display(tight.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaTeX table saved to 'outputs/results/tightness_table.tex'\n",
      "% Auto-generated LaTeX table: Ave PoA (CI), Max PoA, Bound, Gap\n",
      "\\begin{table}[ht!]\n",
      "\\centering\n",
      "\\caption{Average and maximum observed PoA with 95\\% CI, theoretical bounds, and gaps.}\n",
      "\\label{tab:tightness_table_ave_max_bound_gap}\n",
      "\\footnotesize\n",
      "\\renewcommand{\\arraystretch}{1.15}\n",
      "\\begin{tabular}{ccccccccccc} \\toprule\n",
      "\\multirow{2}{*}{$p$} & \\multirow{2}{*}{$n$} & \\multirow{2}{*}{$d$} & \\multicolumn{4}{c}{PS} & \\multicolumn{4}{c}{SV} \\\n",
      "\\cmidrule(lr){4-7} \\cmidrule(lr){8-11}\n",
      " &  &  & Ave PoA (CI) & Max PoA & Upper Bound & Gap & Ave PoA (CI) & Max PoA & Upper Bound & Gap \\\n",
      "\\midrule\n",
      "0.50 & 2 & 2 & 1.069 [1.068, 1.070] & 1.489 & 1.640 & 0.151 & 1.069 [1.068, 1.070] & 1.489 & 1.640 & 0.151 \\\n",
      "0.50 & 2 & 3 & 1.182 [1.178, 1.186] & 2.415 & 3.766 & 1.352 & 1.178 [1.174, 1.182] & 2.415 & 4.137 & 1.722 \\\n",
      "0.50 & 2 & 4 & 1.371 [1.361, 1.381] & 4.422 & 12.402 & 7.979 & 1.350 [1.341, 1.360] & 4.422 & 18.376 & 13.954 \\\n",
      "0.50 & 3 & 2 & 1.051 [1.050, 1.053] & 1.452 & 1.768 & 0.316 & 1.051 [1.050, 1.053] & 1.452 & 1.768 & 0.316 \\\n",
      "0.50 & 3 & 3 & 1.143 [1.139, 1.147] & 2.570 & $*$ & $*$ & 1.144 [1.141, 1.148] & 2.570 & $*$ & $*$ \\\n",
      "0.50 & 3 & 4 & 1.304 [1.295, 1.312] & 8.631 & $*$ & $*$ & 1.301 [1.292, 1.310] & 7.849 & $*$ & $*$ \\\n",
      "0.50 & 4 & 2 & 1.039 [1.039, 1.040] & 1.451 & 1.925 & 0.474 & 1.039 [1.039, 1.040] & 1.451 & 1.925 & 0.474 \\\n",
      "0.50 & 4 & 3 & 1.111 [1.108, 1.114] & 2.413 & $*$ & $*$ & 1.111 [1.108, 1.115] & 2.413 & $*$ & $*$ \\\n",
      "0.50 & 4 & 4 & 1.233 [1.225, 1.240] & 5.495 & $*$ & $*$ & 1.227 [1.220, 1.235] & 5.495 & $*$ & $*$ \\\n",
      "0.90 & 2 & 2 & 1.119 [1.117, 1.121] & 1.852 & 2.392 & 0.540 & 1.119 [1.117, 1.121] & 1.852 & 2.392 & 0.540 \\\n",
      "0.90 & 2 & 3 & 1.305 [1.298, 1.313] & 3.566 & 8.361 & 4.794 & 1.297 [1.290, 1.305] & 3.566 & 10.357 & 6.791 \\\n",
      "0.90 & 2 & 4 & 1.624 [1.605, 1.642] & 6.948 & 38.262 & 31.314 & 1.586 [1.569, 1.603] & 6.948 & 76.498 & 69.550 \\\n",
      "0.90 & 3 & 2 & 1.087 [1.085, 1.089] & 1.887 & 2.443 & 0.557 & 1.087 [1.085, 1.089] & 1.887 & 2.443 & 0.557 \\\n",
      "0.90 & 3 & 3 & 1.240 [1.234, 1.247] & 4.027 & $*$ & $*$ & 1.240 [1.233, 1.247] & 4.027 & $*$ & $*$ \\\n",
      "0.90 & 3 & 4 & 1.486 [1.472, 1.502] & 15.524 & $*$ & $*$ & 1.482 [1.466, 1.497] & 15.524 & $*$ & $*$ \\\n",
      "0.90 & 4 & 2 & 1.064 [1.062, 1.065] & 1.922 & 2.497 & 0.575 & 1.064 [1.062, 1.065] & 1.922 & 2.497 & 0.575 \\\n",
      "0.90 & 4 & 3 & 1.176 [1.171, 1.182] & 3.391 & $*$ & $*$ & 1.175 [1.169, 1.180] & 3.391 & $*$ & $*$ \\\n",
      "0.90 & 4 & 4 & 1.351 [1.340, 1.363] & 12.262 & $*$ & $*$ & 1.347 [1.335, 1.359] & 12.262 & $*$ & $*$ \\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "EPS = 1e-9\n",
    "\n",
    "def format_latex_table_from_tight_v2(\n",
    "    tight_df: pd.DataFrame,\n",
    "    filename: str,\n",
    "    rules: List[str] = [\"PS\", \"SV\"],\n",
    "    digits: int = 3,\n",
    "    highlight_best: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a LaTeX table with, per rule: Ave PoA (CI), Max PoA, Upper Bound, Gap.\n",
    "    Uses your existing columns in `tight`:\n",
    "      - 'p','n','d','rule','observed_avg_poa','avg_ci_low','avg_ci_high',\n",
    "        'observed_max_poa','theory_bound','gap_to_bound_max'\n",
    "    If 'gap_to_bound_max' is absent, computes as theory_bound - observed_max_poa (floored at 0).\n",
    "    \"\"\"\n",
    "    req_cols = [\n",
    "        'p','n','d','Rule',\n",
    "        'observed_avg_poa','avg_ci_low','avg_ci_high',\n",
    "        'observed_max_poa',\n",
    "        'theory_bound'\n",
    "    ]\n",
    "    for c in req_cols:\n",
    "        if c not in tight_df.columns:\n",
    "            raise ValueError(f\"Column '{c}' missing from tight_df\")\n",
    "\n",
    "    df = tight_df.copy()\n",
    "    # Normalize rule labels to upper for matching\n",
    "    # df['Rule'] = df['rule'].astype(str).str.upper()\n",
    "\n",
    "    # Compute gap if missing\n",
    "    if 'gap_to_bound_max' not in df.columns:\n",
    "        df['gap_to_bound_max'] = df['theory_bound'] - df['observed_max_poa']\n",
    "        # Ensure non-negative gap (if desired)\n",
    "        df['gap_to_bound_max'] = df['gap_to_bound_max'].apply(lambda x: x if pd.isna(x) else max(0.0, x))\n",
    "\n",
    "    df_sorted = df.sort_values([\"p\",\"n\",\"d\",\"Rule\"]).reset_index(drop=True)\n",
    "\n",
    "    # --- Header ---\n",
    "    lines = []\n",
    "    lines.append('% Auto-generated LaTeX table: Ave PoA (CI), Max PoA, Bound, Gap')\n",
    "    lines.append('\\\\begin{table}[ht!]')\n",
    "    lines.append('\\\\centering')\n",
    "    lines.append('\\\\caption{Average and maximum observed PoA with 95\\\\% CI, theoretical bounds, and gaps.}')\n",
    "    lines.append('\\\\label{tab:tightness_table_ave_max_bound_gap}')\n",
    "    lines.append('\\\\footnotesize')\n",
    "    lines.append('\\\\renewcommand{\\\\arraystretch}{1.15}')\n",
    "\n",
    "    num_rules = len(rules)\n",
    "    col_spec = 'ccc' + 'cccc' * num_rules\n",
    "\n",
    "    header1 = ['\\\\multirow{2}{*}{$p$}', '\\\\multirow{2}{*}{$n$}', '\\\\multirow{2}{*}{$d$}']\n",
    "    cmidrules = []\n",
    "    header2 = ['','','']\n",
    "\n",
    "    for i, rule_name in enumerate(rules):\n",
    "        header1.append(f'\\\\multicolumn{{4}}{{c}}{{{rule_name}}}')\n",
    "        start_col = 4 + i*4\n",
    "        end_col = 7 + i*4\n",
    "        cmidrules.append(f'\\\\cmidrule(lr){{{start_col}-{end_col}}}')\n",
    "        header2.extend(['Ave PoA (CI)', 'Max PoA', 'Upper Bound', 'Gap'])\n",
    "\n",
    "    lines.append(f'\\\\begin{{tabular}}{{{col_spec}}} \\\\toprule')\n",
    "    lines.append(' & '.join(header1) + ' \\\\')\n",
    "    lines.append(' '.join(cmidrules))\n",
    "    lines.append(' & '.join(header2) + ' \\\\')\n",
    "    lines.append('\\\\midrule')\n",
    "\n",
    "    # --- Body ---\n",
    "    unique_params = list(dict.fromkeys(zip(df_sorted['p'], df_sorted['n'], df_sorted['d'])))\n",
    "\n",
    "    for p_val, n_val, d_val in unique_params:\n",
    "        # Best (min) max PoA among rules for highlighting\n",
    "        row_block = df_sorted[(df_sorted['p']==p_val)&(df_sorted['n']==n_val)&(df_sorted['d']==d_val)]\n",
    "        min_max = np.inf\n",
    "        if highlight_best and not row_block.empty and row_block['observed_max_poa'].notna().any():\n",
    "            min_max = row_block['observed_max_poa'].min()\n",
    "\n",
    "        cells = [f'{p_val:.2f}', f'{int(n_val)}', f'{int(d_val)}']\n",
    "\n",
    "        for rule in rules:\n",
    "            sub = row_block[row_block['Rule']==rule]\n",
    "            if sub.empty:\n",
    "                cells.extend(['$*$','$*$','$*$','$*$'])\n",
    "                continue\n",
    "            r = sub.iloc[0]\n",
    "            # Ave PoA (CI)\n",
    "            ave = r.get('observed_avg_poa', np.nan)\n",
    "            lo = r.get('avg_ci_low', np.nan)\n",
    "            hi = r.get('avg_ci_high', np.nan)\n",
    "            if pd.isna(ave) or pd.isna(lo) or pd.isna(hi):\n",
    "                ave_ci_str = '$*$'\n",
    "            else:\n",
    "                ave_ci_str = f\"{ave:.{digits}f} [{lo:.{digits}f}, {hi:.{digits}f}]\"\n",
    "\n",
    "            # Max PoA with highlight (bold if equal to row min)\n",
    "            maxv = r.get('observed_max_poa', np.nan)\n",
    "            if pd.isna(maxv):\n",
    "                max_str = '$*$'\n",
    "            else:\n",
    "                max_str = f\"{maxv:.{digits}f}\"\n",
    "                if highlight_best and np.isfinite(min_max) and abs(maxv - min_max) < EPS:\n",
    "                    max_str = f\"\\\\textbf{{{max_str}}}\"\n",
    "\n",
    "            # Bound & Gap\n",
    "            bound = r.get('theory_bound', np.nan)\n",
    "            gap = r.get('gap_to_bound_max', np.nan)\n",
    "            bound_str = '$*$' if pd.isna(bound) else f\"{bound:.{digits}f}\"\n",
    "            gap_str = '$*$' if pd.isna(gap) else f\"{gap:.{digits}f}\"\n",
    "\n",
    "            cells.extend([ave_ci_str, max_str, bound_str, gap_str])\n",
    "\n",
    "        lines.append(' & '.join(cells) + ' \\\\')\n",
    "\n",
    "    lines.append('\\\\bottomrule')\n",
    "    lines.append('\\\\end{tabular}')\n",
    "    lines.append('\\\\end{table}')\n",
    "\n",
    "    latex = '\\n'.join(lines)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex)\n",
    "    print(f\"LaTeX table saved to '{filename}'\")\n",
    "    return latex\n",
    "\n",
    "# --- Usage example (uncomment when running in your notebook) ---\n",
    "latex_code = format_latex_table_from_tight_v2(\n",
    "    tight,\n",
    "    filename=str(RESULTS_DIR / 'tightness_table.tex'),\n",
    "    rules=['PS','SV'],\n",
    "    digits=3,\n",
    "    highlight_best=False,\n",
    ")\n",
    "print(latex_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- System Specifications ---\n",
      "OS             : macOS-15.6.1-arm64-arm-64bit\n",
      "CPU            : arm\n",
      "Logical Cores  : 8\n",
      "Physical Cores : 8\n",
      "RAM (GB)       : 16.00\n",
      "Python         : 3.12.7\n",
      "Key Packages   : NumPy v1.26.4, SciPy v1.13.1, pandas v2.2.2, Matplotlib v3.9.2, Seaborn v0.13.2, tqdm v4.66.5, Joblib v1.4.2, Numba v0.60.0\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import joblib\n",
    "import numba\n",
    "\n",
    "# 使用 try-except 来处理可选的 psutil 库\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    psutil = None\n",
    "try:\n",
    "    import seaborn\n",
    "except ImportError:\n",
    "    seaborn = None\n",
    "\n",
    "def get_system_specs():\n",
    "    \"\"\"收集并返回关键的硬件和软件信息。\"\"\"\n",
    "    specs = {}\n",
    "\n",
    "    # 1. 硬件信息\n",
    "    specs['OS'] = platform.platform()\n",
    "    specs['CPU'] = platform.processor()\n",
    "    specs['Logical Cores'] = os.cpu_count()\n",
    "    if psutil:\n",
    "        specs['Physical Cores'] = psutil.cpu_count(logical=False)\n",
    "        ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "        specs['RAM (GB)'] = f\"{ram_gb:.2f}\"\n",
    "    else:\n",
    "        specs['Physical Cores'] = \"N/A (psutil not installed)\"\n",
    "        specs['RAM (GB)'] = \"N/A (psutil not installed)\"\n",
    "\n",
    "    # 2. 软件信息\n",
    "    specs['Python'] = platform.python_version()\n",
    "    \n",
    "    packages = {\n",
    "        \"NumPy\": numpy, \"SciPy\": scipy, \"pandas\": pandas,\n",
    "        \"Matplotlib\": matplotlib, \"Seaborn\": seaborn, \"tqdm\": tqdm,\n",
    "        \"Joblib\": joblib, \"Numba\": numba\n",
    "    }\n",
    "    \n",
    "    package_versions = []\n",
    "    for name, pkg in packages.items():\n",
    "        if pkg:\n",
    "            package_versions.append(f\"{name} v{pkg.__version__}\")\n",
    "    \n",
    "    specs['Key Packages'] = \", \".join(package_versions)\n",
    "\n",
    "    return specs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- System Specifications ---\")\n",
    "    system_info = get_system_specs()\n",
    "    for key, value in system_info.items():\n",
    "        print(f\"{key:<15}: {value}\")\n",
    "    \n",
    "    if not psutil:\n",
    "        print(\"\\n[NOTE] To get Physical Core count and RAM, please install psutil: pip install psutil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
